import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.shapes import MSO_SHAPE
from pptx.dml.color import RGBColor
from fpdf import FPDF
import os

# Configure Google Generative AI

genai.configure(api_key="AIzaSyCvM4yzyrUflRJdug-E9wtV_0ALWCwVGY0")  
model = genai.GenerativeModel('gemini-1.5-flash')  

# Memory to store citations
agent_memory = {}

# PDF Generator Class
class PDFExporter:
    def __init__(self):
        self.pdf = FPDF()
        self.pdf.set_auto_page_break(auto=True, margin=15)
        self.pdf.add_page()
        self.pdf.set_font("Arial", size=12)

    def add_abstract(self, title, abstract, url):
        title = self.sanitize_text(title)
        abstract = self.sanitize_text(abstract)
        url = self.sanitize_text(url)

        self.pdf.set_font("Arial", 'B', 12)
        self.pdf.multi_cell(0, 10, title)
        self.pdf.set_font("Arial", size=11)
        self.pdf.multi_cell(0, 10, f"Abstract: {abstract}\nLink: {url}\n\n")

    def export(self, filename):
        self.pdf.output(filename)

    def sanitize_text(self, text):
        return text.encode('latin1', 'replace').decode('latin1')

# Scraper Agent
def fetch_pubmed_articles(disease, limit=10):
    query = f"reducing {disease} readmission"
    search_url = f"https://pubmed.ncbi.nlm.nih.gov/?term={query.replace(' ', '+')}"
    response = requests.get(search_url)
    soup = BeautifulSoup(response.text, "html.parser")
    articles = soup.select(".docsum-content")[:limit]

    results = []
    for article in articles:
        title_tag = article.select_one("a.docsum-title")
        if not title_tag:
            continue
        title = title_tag.get_text(strip=True)
        article_url = "https://pubmed.ncbi.nlm.nih.gov" + title_tag["href"]
        abstract = fetch_abstract(article_url)
        results.append({"title": title, "url": article_url, "abstract": abstract})
    return results

def fetch_abstract(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")
        abstract_tag = soup.select_one(".abstract-content.selected")
        if abstract_tag:
            return abstract_tag.get_text(strip=True)
        else:
            return "No abstract available."
    except Exception as e:
        return f"Error fetching abstract: {str(e)}"

# Summarizer Agent
def summarize_with_gemini(disease, articles):
    full_text = "\n\n".join([f"Title: {a['title']}\nAbstract: {a['abstract']}" for a in articles])
    prompt = f"""You are an expert summarizer. Your task is to extract actionable clinical and administrative insights.
Disease: {disease}
Summarize the following abstracts:
{full_text}
Output two sections:
1. Clinical Strategy (for doctors): Describe specific interventions, therapies, and diagnostics to prevent readmissions.
2. Administrative Actions (for hospital managers): Propose policy, discharge planning, follow-up procedures, and resource coordination steps."""
    response = model.generate_content(prompt)
    return response.text.strip()

# Deck Builder
def create_deck(summaries):
    prs = Presentation()
    title_slide_layout = prs.slide_layouts[0]
    content_slide_layout = prs.slide_layouts[1]

    # Title slide
    slide = prs.slides.add_slide(title_slide_layout)
    slide.shapes.title.text = "Medical Readmission Reduction Program"
    slide.placeholders[1].text = "Clinical and Administrative Insights Generated by AI"

    for disease, content in summaries.items():
        slide = prs.slides.add_slide(content_slide_layout)
        slide.shapes.title.text = f"{disease} Readmission Reduction"
        textbox = slide.placeholders[1]
        textbox.text = content
        for p in textbox.text_frame.paragraphs:
            for run in p.runs:
                run.font.size = Pt(14)

    final_slide = prs.slides.add_slide(content_slide_layout)
    final_slide.shapes.title.text = "Comprehensive Readmission Program"
    final_slide.placeholders[1].text = "This program combines insights from multiple disease strategies to reduce overall hospital readmission rates."
    prs.save("readmission_summary_deck.pptx")

# ====== STREAMLIT UI ======
st.set_page_config(page_title="Agentic AI - Clinical Readmission Strategist", layout="centered")
st.title("üìö Agentic AI - Medical Readmission Strategy Generator")
st.markdown("Searches PubMed, summarizes using Gemini, and generates PDF + PPTX outputs.")

diseases = st.text_input("Enter diseases (comma separated)", "CHF, Sepsis, UTI, Kidney failure")

if st.button("Generate Summary & Deck"):
    st.info("Processing... Please wait.")
    disease_list = [d.strip() for d in diseases.split(",")]
    summaries = {}
    pdf = PDFExporter()

    for disease in disease_list:
        st.write(f"üîç Processing: **{disease}**")
        articles = fetch_pubmed_articles(disease)
        summary = summarize_with_gemini(disease, articles)
        summaries[disease] = summary

        agent_memory[disease] = [(a['title'], a['url']) for a in articles]

        for a in articles:
            pdf.add_abstract(a['title'], a['abstract'], a['url'])

        st.markdown(f"**{disease} Summary:**")
        st.markdown(summary)

    create_deck(summaries)
    pdf.export("pubmed_abstracts.pdf")

    with open("pubmed_abstracts.pdf", "rb") as f:
        st.download_button("üìÑ Download Abstracts PDF", f, file_name="pubmed_abstracts.pdf")
    with open("readmission_summary_deck.pptx", "rb") as f:
        st.download_button("üìä Download PowerPoint Deck", f, file_name="readmission_summary_deck.pptx")

    st.success("‚úÖ All done!")

    st.markdown("### üîó Citations (Memory)")
    for disease, citations in agent_memory.items():
        st.markdown(f"**{disease}**")
        for title, link in citations:
            st.markdown(f"- [{title}]({link})")
